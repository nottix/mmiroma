\chapter{Conclusioni}
Sulla base dei risultati ottenuti e sui problemi riscontrati durante lo sviluppo, si vogliono effettuare alcune considerazioni.
Per quanto riguarda il modello simulativo, l'adozione di una politica round robin piuttosto che random non comporta alcuna differenza significativa, mentre l'adozione di una politica di tipo least loaded comporta un aumento dell'utilizzazione (e quindi del carico sottoposto al sistema), mentre tendono a diminuire i tempi medi di risposta. L'introduzione di componenti addizionali (il proxy e il link addizionale) tendono a far diminuire le utilizzazioni e le code del sistema, ma non comportano una diminuzione dei tempi di risposta. 
Per quanto concerne il modello analitico invece, si nota come i valori delle utilizzazioni siano molto simili a quelli ottenuti col modello simulativo (le differenze maggiori sono intorno al 4\% e solo nel caso dei dischi), mentre le lunghezze delle code risultano essere piuttosto diverse tra i due modelli (questo potrebbe essere dovuto al fatto che si assume che il carico sia equamente ripartito tra i server e di conseguenza tra i dischi). I tempi medi di residenza inoltre evidenziano come i dischi siano sottoposti a operazioni molto onerose in caso di richieste di Classe 2 e 3. Nel modello simulativo invece le richieste di Classe 2 e 3 sono molto rare e infatti i valori presentati per le richieste di Classe 1 sono sempre più alti rispetto alle restanti classi. Di conseguenza, il modello simulativo riflette meglio la distribuzione non uniforme delle richieste.
Per quanto concerne i problemi riscontrati durante lo sviluppo dell'applicativo, è doveroso sottolineare come l'utilizzo delle distribuzioni per la generazione delle pagine HTML e degli oggetti embedded abbia portato ad ottenere file di dimensioni di centinaia di megabyte, che hanno portato a  tempi medi di residenza spropositati (si vedano i risultati nel modello analitico). Il problema di avere file di queste dimensioni si riflette sicuramente anche nel calcolo del transiente, che come si è visto non consente di trovare un valore tale per cui la media mobile sembra convergere, ma si assiste ad un andamento crescente dei tempi di risposta, come se il sistema fosse ancora in fase di carica. Questo problema si è poi ripercosso anche sul calcolo degli indici nel modello simulativo (e di conseguenza in quello analitico, visto che il fattore lambda è stato ricavato dalla simulazione), poiché sono state escluse solo le prime 100000 osservazioni dalla simulazione (numero non sufficiente per superare il transiente) e di conseguenza i valori ottenuti potrebbero non essere sufficientemente accurati. L'utilizzo di un carico reale, utilizzato nell'esercizio 2 d'esame, avrebbe sicuramente permesso di ottenere dei risultati più affidabili. 
